from google import genai
import os
import json
import re
import time
import random
from typing import List, Dict, Optional

class AIService:
    def __init__(self):
        self.client = genai.Client()
        # å¤šä¸ªå¤‡é€‰æ¨¡å‹ï¼ŒæŒ‰é…é¢å¯ç”¨æ€§æ’åºï¼ˆåŸºäºæµ‹è¯•ç»“æœï¼‰
        self.models = [
            "gemini-2.5-flash-lite-preview-06-17",  # æœ€å…·æˆæœ¬æ•ˆç›Šä¸”æ”¯æŒé«˜ååé‡ â­
            "gemini-2.5-flash",                      # é€‚åº”æ€§æ€ç»´ï¼Œæˆæœ¬æ•ˆç›Š â­
            "gemini-1.5-flash",                      # å¿«é€Ÿè€Œå¤šæ ·çš„æ€§èƒ½ â­
            "gemini-2.0-flash-lite",                 # æˆæœ¬æ•ˆç›Šå’Œä½å»¶è¿Ÿï¼ˆå¤‡ç”¨ï¼‰
            "gemini-1.5-pro",                        # å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆæœ€åå¤‡ç”¨ï¼Œé…é¢é™åˆ¶ï¼‰
        ]
        self.current_model_index = 0

    def _get_current_model(self):
        """è·å–å½“å‰æ¨¡å‹"""
        return self.models[self.current_model_index]

    def _switch_to_next_model(self):
        """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹"""
        self.current_model_index = (self.current_model_index + 1) % len(self.models)
        print(f"ğŸ”„ åˆ‡æ¢åˆ°æ¨¡å‹: {self._get_current_model()}")
        return self._get_current_model()

    async def parse_scene(self, description: str) -> List[Dict]:
        prompt = f"""
        åˆ†æä»¥ä¸‹åœºæ™¯æè¿°ï¼Œæå–æ‰€æœ‰å¯èƒ½çš„å£°éŸ³å…ƒç´ ï¼š
        {description}
        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        - name: å£°éŸ³å…ƒç´ åç§°
        - volume: éŸ³é‡å¤§å°(0-1)
        - position: ä½ç½®("foreground"æˆ–"background")
        - duration: æŒç»­æ—¶é—´(ç§’)
        ç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼š
        [
            {{"name": "rain", "volume": 0.7, "position": "background", "duration": 180.0}},
            {{"name": "cafe_chatter", "volume": 0.5, "position": "foreground", "duration": 180.0}}
        ]
        """
        try:
            response = self.client.models.generate_content(
                model=self._get_current_model(),
                contents=prompt
            )
            raw_response_text = response.text or ""
            print(f"DEBUG: Raw Gemini response for parse_scene: {raw_response_text}")
            json_match = re.search(r'```json\n([\s\S]*?)\n```', raw_response_text)
            if json_match:
                json_string = json_match.group(1).strip()
            else:
                start = raw_response_text.find('[')
                end = raw_response_text.rfind(']')
                if start != -1 and end != -1 and end > start:
                    json_string = raw_response_text[start:end+1].strip()
                else:
                    json_string = raw_response_text.strip()
            print(f"DEBUG: Cleaned JSON string for parsing: >>>{json_string}<<< (length={len(json_string)})")
            elements = json.loads(json_string)
            return elements
        except Exception as e:
            print(f"Error in parse_scene: {str(e)}")
            print(f"ORIGINAL RAW: >>>{raw_response_text if 'raw_response_text' in locals() else ''}<<<")
            raise

    async def generate_options(self, mode: str, user_input: str, stage: str) -> List[str]:
        # åˆå¹¶åçš„ soundscape description prompt
        fallback_options = {
            'audio_atmosphere': ["In a large empty warehouse", "Deep in a lush rainforest", "Urban street corner at night", "Inside a cozy cafe", "On a snowy mountain peak"],
            'audio_elements': ["Rain", "Footsteps", "Birds chirping", "Thunder", "Wind blowing"],
            'audio_style': ["Natural", "Synthetic", "Mixed", "Organic", "Electronic"],
            'music_genre': ["Ambient", "Classical", "Jazz", "Electronic", "Folk"],
            'music_instruments': ["Piano", "Strings", "Synth", "Guitar", "Drums"],
            'music_tempo': ["Slow", "Medium", "Fast", "Variable", "Steady"],
            'music_usage': ["Background", "Focus", "Relaxation", "Study", "Sleep"]
        }
        if stage in ['mood', 'audio_mood']:
            prompt = f"""
List 5 moods for a soundscape. Each should be a single English word or a short phrase (max 2 words), e.g. "Calm", "Mysterious", "Uplifting", "Bittersweet", "Suspenseful". Do not include any scene, sound, or environment words.
Examples: ["Calm", "Dreamy", "Energetic", "Peaceful", "Tense"]
Only return a JSON array of strings.
- mode: {mode}
- user input: {user_input}
"""
        elif stage in ['audio_atmosphere']:
            prompt = f"""
Based on the user's input and mode, generate 5 atmosphere options. The first option should be a concise, standardized version of the user's idea. The remaining options should be closely related variations, each with a slight change or added detail. Do not simply repeat the original input. Do not include any specific sound elements (like rain, footsteps, birds, etc.), only describe the overall scene or environment.

User input: "A cozy cafe on a rainy afternoon"
Examples: [
  "Cozy cafe, rainy afternoon",
  "Warm cafe, rain on windows",
  "Cafe, soft jazz, rainy day",
  "Cafe, fresh coffee aroma, rain",
  "Quiet cafe, foggy windows"
]

Now, for the following user input, generate 5 atmosphere options as above.
User input: {user_input}
Only return a JSON array of strings.
- mode: {mode}
"""
        elif stage in ['audio_elements']:
            prompt = f"""
Based on the user's input and mode, generate 5 sound element options that are closely related to the user's idea, each with a slight variation or added detail. Do not suggest unrelated sounds or events. Do not simply repeat the original input. Do not include any scene or environment words already mentioned in the atmosphere (such as cafe, rain, afternoon, etc.). Only describe specific sounds or events, not the overall scene or mood.

User input: "A cozy cafe on a rainy afternoon"
Atmosphere: ["Cozy cafe, rainy afternoon", "Warm cafe, rain on windows", "Cafe, soft jazz, rainy day", "Cafe, fresh coffee aroma, rain", "Quiet cafe, foggy windows"]
Examples: [
  "Coffee machine steaming",
  "Pages turning",
  "Barista grinding beans",
  "Distant thunder",
  "Muffled conversation"
]

Now, for the following user input, generate 5 similar sound element options as above.
User input: {user_input}
Only return a JSON array of strings.
- mode: {mode}
"""
        else:
            prompt = f"""
You are an expert in soundscape and music design. The user may input in Chinese or English. Your task is:
1. Understand the user's intent and context from the following mode and input.
2. For the stage: {stage}, generate a list of 5 concise, relevant, diverse, and high-quality options in ENGLISH only (even if the user input is in Chinese).
3. Each option should be a short phrase, no more than 10 English words.
4. If the user input is in Chinese, you must first understand it, then output the options in English, not Chinese.
5. Only return a JSON array of strings, e.g. ["option1", "option2", ...]. No extra text.
- mode: {mode}
- user input: {user_input}
"""
        
        # å°è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹
        for model_attempt in range(len(self.models)):
            current_model = self._get_current_model()
            print(f"ğŸ”§ å°è¯•æ¨¡å‹: {current_model}")
            
            max_retries = 2  # æ¯ä¸ªæ¨¡å‹æœ€å¤šé‡è¯•2æ¬¡
            for attempt in range(max_retries):
                try:
                    response = self.client.models.generate_content(
                        model=current_model,
                        contents=prompt
                    )
                    raw_response_text = response.text or ""
                    print(f"DEBUG: Raw Gemini response for generate_options: {raw_response_text}")
                    json_match = re.search(r'```json\\n([\s\S]*?)\\n```', raw_response_text)
                    if json_match:
                        json_string = json_match.group(1).strip()
                    else:
                        start = raw_response_text.find('[')
                        end = raw_response_text.rfind(']')
                        if start != -1 and end != -1 and end > start:
                            json_string = raw_response_text[start:end+1].strip()
                        else:
                            json_string = raw_response_text.strip()
                    print(f"DEBUG: Cleaned JSON string for options: >>>{json_string}<<< (length={len(json_string)})")
                    options = json.loads(json_string)
                    if isinstance(options, list) and all(isinstance(opt, str) for opt in options):
                        return options
                    return fallback_options.get(stage, ["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"])
                except Exception as e:
                    print(f"Error in generate_options (model: {current_model}, attempt {attempt + 1}): {str(e)}")
                    if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                        print(f"âš ï¸  API é…é¢é™åˆ¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                        if attempt < max_retries - 1:
                            wait_time = (2 ** attempt) + random.uniform(1, 3)
                            print(f"â³ ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                            time.sleep(wait_time)
                            continue
                        else:
                            # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹
                            self._switch_to_next_model()
                            break
                    else:
                        print(f"âŒ å…¶ä»–é”™è¯¯ï¼Œä½¿ç”¨ fallback é€‰é¡¹")
                        return fallback_options.get(stage, ["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"])
            # å¦‚æœå½“å‰æ¨¡å‹å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
            if model_attempt < len(self.models) - 1:
                continue
        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†ï¼Œè¿”å› fallback
        print(f"âŒ æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œä½¿ç”¨ fallback é€‰é¡¹")
        return fallback_options.get(stage, ["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"])

    async def generate_musicgen_options(self, stage: str, user_input: str = "") -> List[str]:
        # ä¸º MusicGen æä¾› fallback é€‰é¡¹
        fallback_options = {
            'genre': ["Ambient", "Classical", "Jazz", "Electronic", "Folk"],
            'instruments': ["Piano", "Strings", "Synth", "Guitar", "Drums"],
            'tempo': ["Slow", "Medium", "Fast", "Variable", "Steady"],
            'usage': ["Background", "Focus", "Relaxation", "Study", "Sleep"]
        }
        
        prompt = f"""
You are an expert in music generation. Generate 5 diverse and creative options for the {stage} stage of music generation.
Each option should be a single English word or short phrase (max 3 words).
Only return a JSON array of strings, e.g. ["option1", "option2", ...].
User input: {user_input}
"""
        
        # å°è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹
        for model_attempt in range(len(self.models)):
            current_model = self._get_current_model()
            print(f"ğŸ”§ å°è¯•æ¨¡å‹: {current_model}")
            
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    response = self.client.models.generate_content(
                        model=current_model,
                        contents=prompt
                    )
                    raw_response_text = response.text or ""
                    json_match = re.search(r'```json\\n([\s\S]*?)\\n```', raw_response_text)
                    if json_match:
                        json_string = json_match.group(1).strip()
                    else:
                        start = raw_response_text.find('[')
                        end = raw_response_text.rfind(']')
                        if start != -1 and end != -1 and end > start:
                            json_string = raw_response_text[start:end+1].strip()
                        else:
                            json_string = raw_response_text.strip()
                    options = json.loads(json_string)
                    if isinstance(options, list) and all(isinstance(opt, str) for opt in options):
                        return options
                    return fallback_options.get(stage, ["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"])
                except Exception as e:
                    print(f"Error in generate_musicgen_options (model: {current_model}, attempt {attempt + 1}): {str(e)}")
                    if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                        if attempt < max_retries - 1:
                            wait_time = (2 ** attempt) + random.uniform(1, 3)
                            time.sleep(wait_time)
                            continue
                        else:
                            self._switch_to_next_model()
                            break
                    else:
                        return fallback_options.get(stage, ["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"])
            if model_attempt < len(self.models) - 1:
                continue
        return fallback_options.get(stage, ["Option 1", "Option 2", "Option 3", "Option 4", "Option 5"])

    async def generate_inspiration_chips(self, mode: str, user_input: str = "") -> List[str]:
        """
        ç”Ÿæˆéšæœºçš„inspiration chipsï¼Œç”¨äºMainScreençš„æç¤ºé€‰é¡¹
        """
        prompt = f"""
You are an expert in creating atmospheric and emotional soundscapes. Generate 6 diverse and inspiring prompts that users can click to get started with sound generation. These should be a mix of different types of inspiration:

**Types of inspiration to include:**
1. **Poetic verses** - Short, evocative lines from poetry or literature that capture a mood
2. **Memory fragments** - Personal, nostalgic moments that evoke specific atmospheres
3. **Atmospheric descriptions** - Rich, sensory descriptions of environments
4. **Emotional states** - Abstract feelings and moods
5. **Imaginary scenes** - Creative, fantastical settings
6. **Sensory experiences** - Multi-sensory descriptions

**Requirements:**
- Mix different styles: some poetic, some descriptive, some abstract
- Each prompt should be 5-20 words long
- Make them creative, inspiring, and diverse
- Consider the mode: {mode} (focus, relax, story, music, etc.)
- If user_input is provided, make some prompts related to it
- Avoid generic phrases, be specific and evocative

**Examples of good prompts:**
- "The rain falls like silver threads on cobblestone streets" (poetic)
- "Grandma's kitchen on Sunday morning, cinnamon in the air" (memory)
- "A library where time stands still, dust motes dance in sunbeams" (atmospheric)
- "The quiet before dawn, when the world holds its breath" (emotional)
- "A steampunk workshop where brass gears whisper secrets" (imaginary)
- "Fresh snow crunching underfoot, breath visible in cold air" (sensory)

**Mode-specific considerations:**
- For 'focus': Include concentration, productivity, clarity themes
- For 'relax': Include peace, calm, soothing themes  
- For 'story': Include narrative, dramatic, cinematic themes
- For 'music': Include rhythmic, melodic, harmonic themes

User input: {user_input}

Only return a JSON array of 6 strings, e.g. ["prompt1", "prompt2", ...].
"""
        
        # å°è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹
        for model_attempt in range(len(self.models)):
            current_model = self._get_current_model()
            print(f"ğŸ”§ å°è¯•æ¨¡å‹: {current_model}")
            
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    response = self.client.models.generate_content(
                        model=current_model,
                        contents=prompt
                    )
                    raw_response_text = response.text or ""
                    print(f"DEBUG: Raw Gemini response for generate_inspiration_chips: {raw_response_text}")
                    json_match = re.search(r'```json\\n([\s\S]*?)\\n```', raw_response_text)
                    if json_match:
                        json_string = json_match.group(1).strip()
                    else:
                        start = raw_response_text.find('[')
                        end = raw_response_text.rfind(']')
                        if start != -1 and end != -1 and end > start:
                            json_string = raw_response_text[start:end+1].strip()
                        else:
                            json_string = raw_response_text.strip()
                    print(f"DEBUG: Cleaned JSON string for inspiration chips: >>>{json_string}<<< (length={len(json_string)})")
                    chips = json.loads(json_string)
                    if isinstance(chips, list) and all(isinstance(chip, str) for chip in chips):
                        return chips
                    return self._get_fallback_inspiration_chips()
                except Exception as e:
                    print(f"Error in generate_inspiration_chips (model: {current_model}, attempt {attempt + 1}): {str(e)}")
                    if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                        print(f"âš ï¸  API é…é¢é™åˆ¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                        if attempt < max_retries - 1:
                            wait_time = (2 ** attempt) + random.uniform(1, 3)
                            print(f"â³ ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                            time.sleep(wait_time)
                            continue
                        else:
                            self._switch_to_next_model()
                            break
                    else:
                        print(f"âŒ å…¶ä»–é”™è¯¯ï¼Œä½¿ç”¨ fallback é€‰é¡¹")
                        return self._get_fallback_inspiration_chips()
            if model_attempt < len(self.models) - 1:
                continue
        print(f"âŒ æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œä½¿ç”¨ fallback é€‰é¡¹")
        return self._get_fallback_inspiration_chips()

    def _get_fallback_inspiration_chips(self) -> List[str]:
        """è·å–fallbackçš„inspiration chips"""
        return [
            "The rain falls like silver threads on cobblestone streets",
            "Grandma's kitchen on Sunday morning, cinnamon in the air",
            "A library where time stands still, dust motes dance in sunbeams",
            "The quiet before dawn, when the world holds its breath",
            "A steampunk workshop where brass gears whisper secrets",
            "Fresh snow crunching underfoot, breath visible in cold air",
        ]

    def analyze_music_prompt_layers(self, user_text: str = '', extra_fields: dict = None) -> dict:
        """
        ä½¿ç”¨ LLM åˆ†æç”¨æˆ·è¾“å…¥ï¼Œåˆ†è§£ä¸º genre, style, mood, feeling, instrumentation, tempo, bpm, production_quality, artist_styleã€‚
        ä¼˜å…ˆåˆå¹¶å‰ç«¯ä¼ æ¥çš„ç»“æ„åŒ–å­—æ®µï¼ˆå¦‚ genre, instruments, tempo, usageï¼‰ï¼Œåœ¨ LLM prompt åˆ†ææ—¶å°†è¿™äº›å­—æ®µæ‹¼æ¥åˆ° userInput å‰é¢ã€‚
        """
        extra_fields = extra_fields or {}
        # æ‹¼æ¥ç»“æ„åŒ–å­—æ®µä¸ºå‰ç¼€
        prefix_parts = []
        if extra_fields.get('genre'):
            prefix_parts.append(f"Genre: {extra_fields['genre']}")
        if extra_fields.get('instruments'):
            prefix_parts.append(f"Instruments: {', '.join(extra_fields['instruments'])}")
        if extra_fields.get('tempo'):
            prefix_parts.append(f"Tempo: {extra_fields['tempo']}")
        if extra_fields.get('usage'):
            prefix_parts.append(f"Usage: {extra_fields['usage']}")
        prefix = '. '.join(prefix_parts)
        # æ‹¼æ¥åˆ° user_text å‰é¢
        full_text = (prefix + '. ' if prefix else '') + (user_text or '')
        prompt = '''
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„éŸ³ä¹ç†è®ºå®¶å’ŒMeta MusicGenæ¨¡å‹çš„Promptå·¥ç¨‹å¸ˆã€‚
è¯·å°†ä»¥ä¸‹æ–‡æœ¬è§£æ„ä¸ºéŸ³ä¹ç”Ÿæˆçš„æ ¸å¿ƒå…ƒç´ ï¼Œè¾“å‡ºJSONï¼š
- genre: ç±»å‹ï¼ˆå¦‚ ambient, rock, cinematic, jazz ç­‰ï¼Œè‹±æ–‡ï¼‰
- style: é£æ ¼ï¼ˆå¦‚ 90s alternative, lo-fi, synthwave ç­‰ï¼Œè‹±æ–‡ï¼‰
- mood: æƒ…ç»ªï¼ˆå¦‚ melancholy, peaceful, energetic, epic ç­‰ï¼Œè‹±æ–‡ï¼‰
- feeling: ç»†è…»æ„Ÿè§‰ï¼ˆå¦‚ lonely, nostalgic, reflective, dreamy ç­‰ï¼Œè‹±æ–‡ï¼‰
- instrumentation: ä¹å™¨ï¼ˆå¦‚ acoustic guitar, synth pads, string orchestra ç­‰ï¼Œè‹±æ–‡ï¼Œæ•°ç»„ï¼‰
- tempo: é€Ÿåº¦æè¿°ï¼ˆå¦‚ slow tempo, fast tempo, driving beat ç­‰ï¼Œè‹±æ–‡ï¼‰
- bpm: BPMæ•°å€¼ï¼ˆå¦‚ 120, 95 ç­‰ï¼Œæ•°å­—ï¼‰
- production_quality: åˆ¶ä½œè´¨é‡ï¼ˆå¦‚ high-quality production, vintage recording, clean mix ç­‰ï¼Œè‹±æ–‡ï¼‰
- artist_style: è‰ºæœ¯å®¶é£æ ¼ï¼ˆå¦‚ in the style of Taylor Swift, inspired by Hans Zimmer ç­‰ï¼Œè‹±æ–‡ï¼‰
åªè¿”å›JSONï¼Œæ— éœ€è§£é‡Šã€‚
æ–‡æœ¬ï¼š''' + full_text
        try:
            response = self.client.models.generate_content(
                model=self._get_current_model(),
                contents=prompt
            )
            raw = response.text or ""
            # å°è¯•æå–JSON
            json_match = re.search(r'```json\n([\s\S]*?)\n```', raw)
            if json_match:
                json_string = json_match.group(1).strip()
            else:
                start = raw.find('{')
                end = raw.rfind('}')
                if start != -1 and end != -1 and end > start:
                    json_string = raw[start:end+1].strip()
                else:
                    json_string = raw.strip()
            result = json.loads(json_string)
            # ç”¨ç»“æ„åŒ–å­—æ®µè¡¥å…¨/è¦†ç›– LLM ç»“æœ
            if extra_fields.get('genre'):
                result['genre'] = extra_fields['genre']
            if extra_fields.get('instruments'):
                result['instrumentation'] = extra_fields['instruments']
            if extra_fields.get('tempo'):
                result['tempo'] = extra_fields['tempo']
            if extra_fields.get('usage'):
                result['usage'] = extra_fields['usage']
            return result
        except Exception as e:
            print(f"Error in analyze_music_prompt_layers: {e}")
            print(f"RAW: >>>{raw if 'raw' in locals() else ''}<<<")
            return {}

    def build_high_fidelity_musicgen_prompt(self, genre: str = None, style: str = None, mood: str = None, feeling: str = None, instrumentation: list = None, tempo: str = None, bpm: int = None, production_quality: str = None, artist_style: str = None) -> str:
        """
        æ„å»ºé«˜ä¿çœŸ MusicGen Promptï¼Œåˆ†å±‚è¾“å‡ºï¼Œé€—å·åˆ†éš”ã€‚
        """
        parts = []
        # ç¬¬ä¸€å±‚ï¼šç±»å‹ä¸é£æ ¼
        if genre:
            parts.append(genre)
        if style:
            parts.append(style)
        # ç¬¬äºŒå±‚ï¼šæƒ…ç»ªä¸æ„Ÿè§‰
        if mood:
            parts.append(mood)
        if feeling:
            parts.append(feeling)
        # ç¬¬ä¸‰å±‚ï¼šé…å™¨
        if instrumentation:
            parts.extend(instrumentation)
        # ç¬¬å››å±‚ï¼šé€Ÿåº¦ä¸èŠ‚å¥
        if tempo:
            parts.append(tempo)
        if bpm:
            parts.append(f"{bpm} BPM")
        # ç¬¬äº”å±‚ï¼šåˆ¶ä½œè´¨é‡ä¸è‰ºæœ¯å®¶é£æ ¼
        if production_quality:
            parts.append(production_quality)
        if artist_style:
            parts.append(artist_style)
        # ç»“å°¾è¡¥å……
        parts.append("high-quality, rich, layered, immersive music")
        return ", ".join([str(p) for p in parts if p is not None])

    def analyze_audiogen_prompt_layers(self, user_text: str = '', extra_fields: dict = None) -> dict:
        """
        ä½¿ç”¨ LLM åˆ†æç”¨æˆ·è¾“å…¥ï¼Œåˆ†è§£ä¸º AudioGen äº”å¤§æ”¯æŸ±ï¼špitch, pattern, intensity, acoustic, locationã€‚
        ä¼˜å…ˆåˆå¹¶å‰ç«¯ä¼ æ¥çš„ç»“æ„åŒ–å­—æ®µï¼Œåœ¨ LLM prompt åˆ†ææ—¶å°†è¿™äº›å­—æ®µæ‹¼æ¥åˆ° user_text å‰é¢ã€‚
        """
        extra_fields = extra_fields or {}
        prefix_parts = []
        if extra_fields.get('pitch'):
            prefix_parts.append(f"Pitch: {extra_fields['pitch']}")
        if extra_fields.get('pattern'):
            prefix_parts.append(f"Pattern: {extra_fields['pattern']}")
        if extra_fields.get('intensity'):
            prefix_parts.append(f"Intensity: {extra_fields['intensity']}")
        if extra_fields.get('acoustic'):
            prefix_parts.append(f"Acoustic: {extra_fields['acoustic']}")
        if extra_fields.get('location'):
            prefix_parts.append(f"Location: {extra_fields['location']}")
        prefix = '. '.join(prefix_parts)
        full_text = (prefix + '. ' if prefix else '') + (user_text or '')
        prompt = '''
ä½ æ˜¯ä¸€ä½ä¸–ç•Œé¡¶çº§çš„éŸ³æ•ˆæç¤ºè¯å·¥ç¨‹å¸ˆï¼Œä¸“ä¸ºMeta AudioGenæœåŠ¡ã€‚è¯·å°†ä»¥ä¸‹æ–‡æœ¬è§£æ„ä¸ºäº”å¤§æ”¯æŸ±ï¼š
- pitch: å£°éŸ³çš„é¢‘ç‡ï¼ˆå¦‚ high-pitched, deep rumble, low growl ç­‰ï¼Œè‹±æ–‡ï¼‰
- pattern: èŠ‚å¥/é‡å¤æ€§ï¼ˆå¦‚ intermittent beeping, continuous hum, rhythmic tapping ç­‰ï¼Œè‹±æ–‡ï¼‰
- intensity: éŸ³é‡/åŠ›åº¦ï¼ˆå¦‚ faint, distant explosion, deafening roar, gradually increasing in volume ç­‰ï¼Œè‹±æ–‡ï¼‰
- acoustic: å£°å­¦ç‰¹æ€§ï¼ˆå¦‚ muffled sound, crisp and clear, metallic echo, hollow wooden knock ç­‰ï¼Œè‹±æ–‡ï¼‰
- location: ä½ç½®/ç¯å¢ƒï¼ˆå¦‚ in a vast, empty cavern, on a busy city street, inside a small wooden box ç­‰ï¼Œè‹±æ–‡ï¼‰
åªè¿”å›JSONï¼Œæ— éœ€è§£é‡Šã€‚
æ–‡æœ¬ï¼š''' + full_text
        try:
            response = self.client.models.generate_content(
                model=self._get_current_model(),
                contents=prompt
            )
            raw = response.text or ""
            json_match = re.search(r'```json\n([\s\S]*?)\n```', raw)
            if json_match:
                json_string = json_match.group(1).strip()
            else:
                start = raw.find('{')
                end = raw.rfind('}')
                if start != -1 and end != -1 and end > start:
                    json_string = raw[start:end+1].strip()
                else:
                    json_string = raw.strip()
            result = json.loads(json_string)
            # ç”¨ç»“æ„åŒ–å­—æ®µè¡¥å…¨/è¦†ç›– LLM ç»“æœ
            for k in ['pitch','pattern','intensity','acoustic','location']:
                if extra_fields.get(k):
                    result[k] = extra_fields[k]
            return result
        except Exception as e:
            print(f"Error in analyze_audiogen_prompt_layers: {e}")
            print(f"RAW: >>>{raw if 'raw' in locals() else ''}<<<")
            return {}

    def build_high_fidelity_audiogen_prompt(
        self,
        pitch: str = None,
        pattern: str = None,
        intensity: str = None,
        acoustic: str = None,
        location: str = None,
        extra: str = None
    ) -> str:
        """
        æ„å»ºé«˜ä¿çœŸ AudioGen Promptï¼Œåˆ†å±‚è¾“å‡ºï¼Œé€—å·åˆ†éš”ã€‚
        """
        parts = []
        if pitch:
            parts.append(pitch)
        if pattern:
            parts.append(pattern)
        if intensity:
            parts.append(intensity)
        if acoustic:
            parts.append(acoustic)
        if location:
            parts.append(location)
        if extra:
            parts.append(extra)
        return ', '.join([str(p) for p in parts if p])

def get_instruments_from_ai(atmosphere: Optional[str], mood: Optional[str], elements: Optional[List[str]], user_input: Optional[str], reference_era: Optional[str]) -> List[str]:
    """
    è°ƒç”¨ AI è¡¥å…¨ä¹å™¨ï¼ˆæ­¤å¤„ä¸º mockï¼Œå¯å¯¹æ¥ Gemini/GPT/OpenAIï¼‰ã€‚
    """
    # TODO: å®é™…å¯ç”¨ OpenAI/Gemini API è°ƒç”¨
    # prompt = f"""
    # Given the following user preferences for a music generation model:
    # - Atmosphere: {atmosphere}
    # - Mood: {mood}
    # - Elements: {', '.join(elements or [])}
    # - User input: {user_input}
    # - Reference era: {reference_era}
    # Suggest a suitable combination of 2-4 musical instruments (in English, comma separated, no extra words).
    # """
    # ...
    # return instruments_list
    return ["acoustic guitar", "piano", "soft synth pad"]

def build_musicgen_prompt(
    atmosphere: Optional[str],
    mood: Optional[str],
    elements: Optional[List[str]],
    user_input: Optional[str],
    instruments: Optional[List[str]],
    tempo: Optional[str] = None,
    reference_era: Optional[str] = None
) -> str:
    parts = []
    if atmosphere:
        parts.append(atmosphere)
    if mood:
        parts.append(mood)
    if elements:
        parts.append("with elements like " + ", ".join(elements))
    if instruments:
        parts.append("featuring " + ", ".join(instruments))
    if tempo:
        parts.append(f"tempo: {tempo}")
    if reference_era:
        parts.append(f"in the style of {reference_era}")
    if user_input:
        parts.append(user_input)
    parts.append("high-quality, rich, layered, immersive music")
    return ", ".join(parts)

def build_audiogen_prompt(
    subject: str,
    action: str,
    details: str = "",
    environment: str = "",
    extra: str = ""
) -> str:
    """
    ç»“æ„åŒ–æ‹¼æ¥ AudioGen promptï¼Œé€‚ç”¨äºéŸ³æ•ˆ/ç¯å¢ƒéŸ³ç”Ÿæˆã€‚
    """
    prompt = ""
    if details:
        prompt += f"{details} "
    prompt += f"{subject} {action}"
    if environment:
        prompt += f" {environment}"
    if extra:
        prompt += f", {extra}"
    prompt = prompt.strip().capitalize() + "."
    return prompt

# Create singleton instance
ai_service = AIService() 